{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>\n",
    "\n",
    "\n",
    "![mql](images/emdros.png)\n",
    "\n",
    "# CALAP from MQL into TF\n",
    "\n",
    "This notebook can read an\n",
    "[MQL](https://emdros.org/mql.html)\n",
    "dump of a version of the CALAP (Peshitta)\n",
    "and transform it in a Text-Fabric\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric)\n",
    "resource.\n",
    "\n",
    "The dump is obtained from the DANS archive, the dataset\n",
    "*Computer-Assisted Linguistic Analysis of the Peshitta*\n",
    "by Peursen, Prof. Dr. W.T. van (Eep Talstra Centre for Bible And Computing, VU University Amsterdam), 2005,\n",
    "with [DOI 10.17026/dans-zv9-w9d2](https://doi.org/10.17026/dans-zv9-w9d2).\n",
    "\n",
    "**N.B.:**\n",
    "There is an error in the dump: the last monad (slot) is 53920, but the last book is declared to reach\n",
    "until the non-existent slot 53921:\n",
    "\n",
    "```\n",
    "CREATE OBJECT\n",
    "FROM MONADS =  { 35794-53920 } \n",
    "WITH ID_D = 144485\n",
    "[book\n",
    "  book := Sirach;\n",
    "]\n",
    "GO\n",
    "```\n",
    "\n",
    "The correction consists of replacing `53921` by `53920`, here, in one place only (line 503).\n",
    "We have corrected this manually and bzipped the result and stored it in the *sources* subdirectory\n",
    "of these repo.\n",
    "\n",
    "The source only has the text in transliteration, in the feature `surface_consonants`.\n",
    "We provide a key to the transliteration and a feature `cons` that contains the backliterated unicode strings.\n",
    "\n",
    "<img align=\"left\" src=\"images/peshitta.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from shutil import rmtree\n",
    "from tf.fabric import Fabric\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PROJECT = 'calap'\n",
    "VERSION = '2014'\n",
    "\n",
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, PROJECT)\n",
    "\n",
    "thisSource = '{}/source/{}'.format(thisRepo, VERSION)\n",
    "mqlzFile = '{}/{}.mql.bz2'.format(thisSource, PROJECT)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisTempSource = '{}/source'.format(thisTemp)\n",
    "mqlFile = '{}/{}.mql'.format(thisTempSource, PROJECT)\n",
    "thisTempTf = '{}/tf'.format(thisTemp)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only update if and when needed, or force update of everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.00s \tSource /Users/dirk/github/etcbc/calap/source/2014/calap.mql.bz2 exists\n",
      "|       0.00s \tDestination /Users/dirk/github/etcbc/calap/tf/2014/.tf/otype.tfx exists\n",
      "|       0.00s \tDestination /Users/dirk/github/etcbc/calap/tf/2014/.tf/otype.tfx up to date\n",
      "The text fabric files must be updated\n"
     ]
    }
   ],
   "source": [
    "testFile = '{}/.tf/otype.tfx'.format(thisTf)\n",
    "(good, work) = utils.mustRun(mqlzFile, '{}/.tf/otype.tfx'.format(thisTf), force=FORCE)\n",
    "print(f'The text fabric files {\"must be updated\" if good else \"are up to date\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the Text-Fabric slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The oText feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slotType = 'word'\n",
    "\n",
    "featureMetaData = dict(\n",
    "    project='CALAP and TURGAMA',\n",
    "    organizations='Peshitta Institute Leiden; Werkgroep Informatica at the Vrije Universiteit Amsterdam (WIVU)',\n",
    "    projectPeriod='1999-2005, 2005-2010',\n",
    "    projectUrl='http://www.nwo.nl/onderzoek-en-resultaten/onderzoeksprojecten/78/1900123778.html',\n",
    "    encoders='Janet Dyk, Percy van Keulen, Wido van Peursen, Constantijn Sikkel, HendrikJan Bosman, Konrad Jenner, Eep Talstra, Dirk Bakker, Jeffrey A. Volkmer, Ariel Gutman',\n",
    "    language='Syriac',\n",
    "    iso639='syc',\n",
    "    dataset='CALAP',\n",
    "    version=VERSION,\n",
    "    datasetName='Computer-Assisted Linguistic Analysis of the Peshitta',\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    converter='Dirk Roorda (TF)',\n",
    ")\n",
    "\n",
    "oText = {\n",
    "    '': {\n",
    "        '': '''\n",
    "@fmt:text-trans-full={surface_consonants} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    },\n",
    "    '2014': '''\n",
    "@fmt:text-trans-full={surface_consonants} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function selects the proper otext material, falling back on a default if nothing \n",
    "appropriate has been specified in `oText`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.04s INFO: otext feature information found\n",
      "|       0.04s \tfmt:text-trans-full  = \"{surface_consonants} \"\n",
      "|       0.04s \tsectionFeatures      = \"book,chapter,verse\"\n",
      "|       0.04s \tsectionTypes         = \"book,chapter,verse\"\n"
     ]
    }
   ],
   "source": [
    "thisOtext = oText.get(VERSION, oText[''])\n",
    "\n",
    "if thisOtext is oText['']:\n",
    "    utils.caption(0, 'WARNING: no otext feature info provided, using a meager default value')\n",
    "    otextInfo = {}\n",
    "else:\n",
    "    utils.caption(0, 'INFO: otext feature information found')\n",
    "    otextInfo = dict(line[1:].split('=', 1) for line in thisOtext.strip('\\n').split('\\n'))\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        utils.caption(0, '\\t{:<20} = \"{}\"'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The program has several stages:\n",
    "   \n",
    "1. **prepare** the source (utils.bunzip if needed)\n",
    "1. **convert** convert the MQL file into a text-fabric dataset\n",
    "1. **differences** (informational)\n",
    "1. **deliver** the TF data at its destination directory\n",
    "1. **compile** all TF features to binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "Check the source, utils.bunzip it if needed, empty the result directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.06s bunzipping /Users/dirk/github/etcbc/calap/source/2014/calap.mql.bz2 ...\n",
      "|       0.06s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|       0.06s Done\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(thisTempSource):\n",
    "    os.makedirs(thisTempSource)\n",
    "\n",
    "utils.caption(0, 'bunzipping {} ...'.format(mqlzFile))\n",
    "utils.bunzip(mqlzFile, mqlFile)\n",
    "utils.caption(0, 'Done')\n",
    "\n",
    "if os.path.exists(thisTempTf): rmtree(thisTempTf)\n",
    "os.makedirs(thisTempTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQL to Text-Fabric\n",
    "Transform the collected information in feature-like data-structures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Parsing mql source ...\n",
      "  0.00s \t\tenum boolean\n",
      "  0.00s \t\tenum lexical_set_e\n",
      "  0.00s \t\tenum phrase_type_e\n",
      "  0.00s \t\tenum phrase_atom_type_e\n",
      "  0.00s \t\tenum phrase_function_e\n",
      "  0.01s \t\tenum book_name_e\n",
      "  0.01s \t\tenum part_of_speech_e\n",
      "  0.01s \t\tenum gender_e\n",
      "  0.01s \t\tenum number_e\n",
      "  0.01s \t\tenum person_e\n",
      "  0.01s \t\tenum stem_e\n",
      "  0.01s \t\tenum state_e\n",
      "  0.01s \t\tenum voice_e\n",
      "  0.01s \t\tenum determination_e\n",
      "  0.01s \t\tenum phrase_atom_relation_e\n",
      "  0.01s \t\tenum subphrase_type_e\n",
      "  0.01s \t\tenum subphrase_kind_e\n",
      "  0.01s \t\tenum clause_type_e\n",
      "  0.01s \t\tenum clause_atom_type_e\n",
      "  0.01s \t\tenum clause_constituent_relation_e\n",
      "  0.01s \t\tenum tense_e\n",
      "  0.02s \t\totype book\n",
      "  0.02s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.02s \t\totype verse\n",
      "  0.02s \t\t\tfeature verse_label (str) =def= \"\" : node\n",
      "  0.02s \t\t\tfeature verse (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.02s \t\totype chapter\n",
      "  0.02s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.02s \t\totype word\n",
      "  0.02s \t\t\tfeature vpm (str) =def= \"\" : node\n",
      "  0.02s \t\t\tfeature voice (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature vix (str) =def= \"\" : node\n",
      "  0.03s \t\t\tfeature vbs (str) =def= \"\" : node\n",
      "  0.03s \t\t\tfeature vbe (str) =def= \"\" : node\n",
      "  0.03s \t\t\tfeature tense (str) =def= NA : node\n",
      "  0.03s \t\t\tfeature surface_consonants (str) =def= \"\" : node\n",
      "  0.03s \t\t\tfeature stem (str) =def= NA : node\n",
      "  0.03s \t\t\tfeature state (str) =def= NA : node\n",
      "  0.03s \t\t\tfeature psp (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature prs (str) =def= \"\" : node\n",
      "  0.04s \t\t\tfeature pfx (str) =def= \"\" : node\n",
      "  0.04s \t\t\tfeature pfm (str) =def= \"\" : node\n",
      "  0.04s \t\t\tfeature person (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature pdpsp (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature number (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature nme (str) =def= \"\" : node\n",
      "  0.04s \t\t\tfeature morph_state (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature lexeme (str) =def= \"\" : node\n",
      "  0.04s \t\t\tfeature gender (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature frv (str) =def= \"\" : node\n",
      "  0.05s \t\t\tfeature emf (str) =def= \"\" : node\n",
      "  0.05s \t\t\tfeature analyzed_form (str) =def= \"\" : node\n",
      "  0.05s \t\totype phrase_atom\n",
      "  0.05s \t\t\tfeature phrase_atom_type (str) =def= VP : node\n",
      "  0.06s \t\t\tfeature phrase_atom_relation (str) =def= Appo : node\n",
      "  0.06s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.06s \t\t\tfeature is_apposition (str) =def= false : node\n",
      "  0.06s \t\t\tfeature determination (str) =def= NA : node\n",
      "  0.06s \t\totype phrase\n",
      "  0.06s \t\t\tfeature phrase_type (str) =def= VP : node\n",
      "  0.06s \t\t\tfeature phrase_function (str) =def= none : node\n",
      "  0.06s \t\t\tfeature is_apposition (str) =def= false : node\n",
      "  0.07s \t\totype clause_atom\n",
      "  3.74s \tline   1000000\n",
      "  7.16s \tline   2000000\n",
      "  8.76s 2575004 lines parsed\n",
      "  8.76s 3 objects of type book\n",
      "  8.76s 2774 objects of type verse\n",
      "  8.76s 97 objects of type chapter\n",
      "  8.76s 53920 objects of type word\n",
      "  8.76s 41385 objects of type phrase_atom\n",
      "  8.76s 34895 objects of type phrase\n",
      "  8.76s 11411 objects of type clause_atom\n",
      "  8.76s Making TF data ...\n",
      "  8.76s Monad - idd mapping ...\n",
      "  8.81s Removing holes in the monad sequence\n",
      "  8.84s maxSlot=53920\n",
      "  8.84s Node mapping and otype ...\n",
      "  8.88s oslots ...\n",
      "  9.12s metadata ...\n",
      "  9.12s features ...\n",
      "  9.12s \tfeatures from words\n",
      "  9.93s \t    53920 words\n",
      "  9.93s \tfeatures from books\n",
      "  9.93s \t        3 books\n",
      "  9.93s \tfeatures from chapters\n",
      "  9.93s \t       97 chapters\n",
      "  9.93s \tfeatures from clause_atoms\n",
      "  9.94s \t    11411 clause_atoms\n",
      "  9.94s \tfeatures from phrases\n",
      "    10s \t    34895 phrases\n",
      "    10s \tfeatures from phrase_atoms\n",
      "    10s \t    41385 phrase_atoms\n",
      "    10s \tfeatures from verses\n",
      "    10s \t     2774 verses\n",
      "   |     0.10s T analyzed_form        to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.01s T book                 to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.01s T chapter              to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T determination        to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T emf                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T frv                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T gender               to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.13s T is_apposition        to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T lexeme               to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T morph_state          to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T nme                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T number               to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.06s T otype                to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T pdpsp                to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T person               to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T pfm                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.12s T pfx                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T phrase_atom_relation to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T phrase_atom_type     to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.07s T phrase_function      to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.07s T phrase_type          to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T prs                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T psp                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T state                to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T stem                 to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T surface_consonants   to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.10s T tense                to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T vbe                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.09s T vbs                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.01s T verse                to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.01s T verse_label          to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.11s T vix                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.11s T voice                to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.11s T vpm                  to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.34s T oslots               to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.00s M mother               to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n",
      "   |     0.00s M otext                to /Users/dirk/github/etcbc/calap/_temp/2014/tf\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.importMQL(mqlFile, slotType=slotType, otext=otextInfo, meta=featureMetaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         14s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|         14s \tno features to add\n",
      "|         14s \t2 features to delete\n",
      "|         14s \t\tbook@en\n",
      "|         14s \t\tcons\n",
      "|         14s \t37 features in common\n",
      "|         14s analyzed_form             ... no changes\n",
      "|         14s book                      ... no changes\n",
      "|         14s chapter                   ... no changes\n",
      "|         14s determination             ... no changes\n",
      "|         14s emf                       ... no changes\n",
      "|         14s frv                       ... no changes\n",
      "|         14s gender                    ... no changes\n",
      "|         14s is_apposition             ... no changes\n",
      "|         14s lexeme                    ... no changes\n",
      "|         14s morph_state               ... no changes\n",
      "|         14s mother                    ... no changes\n",
      "|         14s nme                       ... no changes\n",
      "|         14s number                    ... no changes\n",
      "|         14s oslots                    ... no changes\n",
      "|         14s otext                     ... differences\n",
      "|         14s \tline      6 OLD -->@dateWritten=2018-01-29T18:59:43Z<--\n",
      "|         14s \tline      6 NEW -->@encoders=Janet Dyk, Percy van Keulen, W ...<--\n",
      "|         14s \tline      7 OLD -->@encoders=Janet Dyk, Percy van Keulen, W ...<--\n",
      "|         14s \tline      7 NEW -->@fmt:text-trans-full={surface_consonants ...<--\n",
      "|         14s \tline      8 OLD -->@fmt:text-orig-full={cons} <--\n",
      "|         14s \tline      8 NEW -->@iso639=syc<--\n",
      "|         14s \tline      9 OLD -->@fmt:text-trans-full={surface_consonants ...<--\n",
      "|         14s \tline      9 NEW -->@language=Syriac<--\n",
      "\n",
      "|         14s otype                     ... no changes\n",
      "|         14s pdpsp                     ... no changes\n",
      "|         15s person                    ... no changes\n",
      "|         15s pfm                       ... no changes\n",
      "|         15s pfx                       ... no changes\n",
      "|         15s phrase_atom_relation      ... no changes\n",
      "|         15s phrase_atom_type          ... no changes\n",
      "|         15s phrase_function           ... no changes\n",
      "|         15s phrase_type               ... no changes\n",
      "|         15s prs                       ... no changes\n",
      "|         15s psp                       ... no changes\n",
      "|         15s state                     ... no changes\n",
      "|         15s stem                      ... no changes\n",
      "|         15s surface_consonants        ... no changes\n",
      "|         15s tense                     ... no changes\n",
      "|         15s vbe                       ... no changes\n",
      "|         15s vbs                       ... no changes\n",
      "|         15s verse                     ... no changes\n",
      "|         15s verse_label               ... no changes\n",
      "|         15s vix                       ... no changes\n",
      "|         15s voice                     ... no changes\n",
      "|         15s vpm                       ... no changes\n",
      "|         15s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver \n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         15s Deliver data set to /Users/dirk/github/etcbc/calap/tf/2014                     .\n",
      "..............................................................................................\n"
     ]
    }
   ],
   "source": [
    "utils.deliverDataset(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "Just to see whether everything loads and the pre-computing of extra information works out.\n",
    "Moreover, if you want to work with these features, then the pre-computing has already been done, and everything is quicker in subsequent runs.\n",
    "\n",
    "We issue load statement to trigger the pre-computing of extra data.\n",
    "Note that all features specified text formats in the `otext` config feature,\n",
    "will be loaded, as well as the features for sections.\n",
    "\n",
    "At that point we have access to the full list of features.\n",
    "We grab them and are going to load them all! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         15s Load and compile standard TF features                                          .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.1.3\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "37 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.15s T otype                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.83s T oslots               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s T book                 from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s T chapter              from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s T verse                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.29s T surface_consonants   from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |      |     0.11s C __levels__           from otype, oslots\n",
      "   |      |     1.74s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.11s C __rank__             from otype, __order__\n",
      "   |      |     1.66s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     0.54s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     0.39s C __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s M otext                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |      |     0.03s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.00s Feature overview: 34 for nodes; 1 for edges; 2 configs; 7 computed\n",
      "  5.91s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".         21s Load and compile all other TF features                                         .\n",
      "..............................................................................................\n",
      "   |     0.00s Feature overview: 34 for nodes; 1 for edges; 2 configs; 7 computed\n",
      "  0.00s loading features ...\n",
      "   |     0.19s T analyzed_form        from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.15s T determination        from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.17s T emf                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.23s T frv                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.23s T gender               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.24s T is_apposition        from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.18s T lexeme               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.18s T morph_state          from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.14s T nme                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.18s T number               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.28s T pdpsp                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.21s T person               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.19s T pfm                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.19s T pfx                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.14s T phrase_atom_relation from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.22s T phrase_atom_type     from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.15s T phrase_function      from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.14s T phrase_type          from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.20s T prs                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.23s T psp                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.19s T state                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.18s T stem                 from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.18s T tense                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.23s T vbe                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.20s T vbs                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s T verse_label          from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.20s T vix                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.19s T voice                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.23s T vpm                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.00s Feature overview: 34 for nodes; 1 for edges; 2 configs; 7 computed\n",
      "  5.49s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile standard TF features')\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('')\n",
    "\n",
    "utils.caption(4, 'Load and compile all other TF features')\n",
    "allFeatures = TF.explore(silent=False, show=True)\n",
    "loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "api = TF.load(loadableFeatures)\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add unicode text and English book names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "syriacMapping = {\n",
    "    '>': \"\\u0710\", # alaph\n",
    "    'B': \"\\u0712\", # beth\n",
    "    'G': \"\\u0713\", # gamal\n",
    "    'D': \"\\u0715\", # dalat\n",
    "    'H': \"\\u0717\", # he\n",
    "    'W': \"\\u0718\", # waw\n",
    "    'Z': \"\\u0719\", # zain\n",
    "    'X': \"\\u071A\", # heth\n",
    "    'V': \"\\u071B\", # teth\n",
    "    'J': \"\\u071D\", # yudh\n",
    "    'K': \"\\u071F\", # kaph\n",
    "    'L': \"\\u0720\", # lamadh\n",
    "    'M': \"\\u0721\", # mim\n",
    "    'N': \"\\u0722\", # nun\n",
    "    'S': \"\\u0723\", # semkath\n",
    "    '<': \"\\u0725\", # e\n",
    "    'P': \"\\u0726\", # pe\n",
    "    'Y': \"\\u0728\", # sadhe\n",
    "    'Q': \"\\u0729\", # qaph\n",
    "    'R': \"\\u072A\", # rish\n",
    "    'C': \"\\u072B\", # shin\n",
    "    'T': \"\\u072C\", # taw\n",
    "    's': \"\\u0724\", # semkath final\n",
    "    'p': \"\\u0727\", # pe reversed\n",
    "}\n",
    "\n",
    "def syriac(translit): return ''.join(syriacMapping.get(c,c) for c in translit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData={\n",
    "    '': featureMetaData,\n",
    "    'cons': {\n",
    "        'valueType': 'str',\n",
    "        'source': 'feature surface_consonants',\n",
    "        'method': 'back transliteration',\n",
    "    },\n",
    "    'book@en': {\n",
    "        'valueType': 'str',\n",
    "        'source': 'feature book',\n",
    "        'method': 'copy',\n",
    "    },\n",
    "}\n",
    "\n",
    "metaData['otext'] = dict()\n",
    "metaData['otext'].update(T.config)\n",
    "metaData['otext'].update({'fmt:text-orig-full': '{cons} '})\n",
    "\n",
    "nodeFeatures = {}\n",
    "edgeFeatures = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = {}\n",
    "bookEn = {}\n",
    "for n in N():\n",
    "    sf = F.surface_consonants.v(n)\n",
    "    if sf != None:\n",
    "        cons[n] = syriac(sf)\n",
    "for n in F.otype.s('book'):\n",
    "    bookEn[n] = F.book.v(n)\n",
    "nodeFeatures['cons'] = cons\n",
    "nodeFeatures['book@en'] = bookEn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.00s T book@en              to /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.16s T cons                 to /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.00s M otext                to /Users/dirk/github/etcbc/calap/tf/2014\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=thisTf, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         27s Load and compile standard TF features                                          .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.1.3\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "39 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.24s T cons                 from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.00s M otext                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |      |     0.02s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.00s T book@en              from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.00s Feature overview: 36 for nodes; 1 for edges; 2 configs; 7 computed\n",
      "  0.68s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".         28s Load and compile all other TF features                                         .\n",
      "..............................................................................................\n",
      "   |     0.00s Feature overview: 36 for nodes; 1 for edges; 2 configs; 7 computed\n",
      "  0.00s loading features ...\n",
      "   |     0.03s B analyzed_form        from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B determination        from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B emf                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B frv                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.03s B gender               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.04s B is_apposition        from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.03s B lexeme               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.03s B morph_state          from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B nme                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.03s B number               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.03s B pdpsp                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.03s B person               from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s B pfm                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s B pfx                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B phrase_atom_relation from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B phrase_atom_type     from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s B phrase_function      from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s B phrase_type          from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.01s B prs                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B psp                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B state                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.03s B stem                 from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B tense                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B vbe                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B vbs                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.00s B verse_label          from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B vix                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B voice                from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.02s B vpm                  from /Users/dirk/github/etcbc/calap/tf/2014\n",
      "   |     0.00s Feature overview: 36 for nodes; 1 for edges; 2 configs; 7 computed\n",
      "  0.68s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile standard TF features')\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('')\n",
    "\n",
    "utils.caption(4, 'Load and compile all other TF features')\n",
    "allFeatures = TF.explore(silent=False, show=True)\n",
    "loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "api = TF.load(loadableFeatures)\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         29s Basic test                                                                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".         29s First verse in all formats                                                     .\n",
      "..............................................................................................\n",
      "text-trans-full\n",
      "\tW MLK> DWJD S>B W <L B CNJ> W MKSJN HWW \n",
      "text-orig-full\n",
      "\tܘ ܡܠܟܐ ܕܘܝܕ ܣܐܒ ܘ ܥܠ ܒ ܫܢܝܐ ܘ ܡܟܣܝܢ ܗܘܘ \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Basic test')\n",
    "utils.caption(4, 'First verse in all formats')\n",
    "for fmt in T.formats:\n",
    "    utils.caption(0, '{}'.format(fmt), continuation=True)\n",
    "    utils.caption(0, '\\t{}'.format(T.text(range(1,12), fmt=fmt)), continuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('noun', 18087),\n",
       " ('preposition', 13991),\n",
       " ('verb', 9744),\n",
       " ('conjunction', 7270),\n",
       " ('pronoun', 1553),\n",
       " ('adjective', 1463),\n",
       " ('negative', 1123),\n",
       " ('adverb', 511),\n",
       " ('interjection', 136),\n",
       " ('interrogative', 42))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.psp.freqList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('VP', 9259),\n",
       " ('CP', 8441),\n",
       " ('PP', 7418),\n",
       " ('NP', 5452),\n",
       " ('NegP', 1113),\n",
       " ('PrNP', 1012),\n",
       " ('PPrP', 951),\n",
       " ('AdvP', 439),\n",
       " ('AdjP', 396),\n",
       " ('IPrP', 176),\n",
       " ('InjP', 136),\n",
       " ('DPrP', 85),\n",
       " ('InrP', 17))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.phrase_type.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate full text locally\n",
    "\n",
    "We generate the full text with book, chapter and verse divisions, transliterated and in unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fmt in T.formats:\n",
    "    with open(f'{thisTemp}/{fmt}.txt', 'w') as fh:\n",
    "        for b in F.otype.s('book'):\n",
    "            book = T.sectionFromNode(b)[0]\n",
    "            fh.write(f'\\n\\nBOOK {book}\\n')\n",
    "            for c in L.d(b, otype='chapter'):\n",
    "                chapter = T.sectionFromNode(c)[1]\n",
    "                fh.write(f'\\n{book} {chapter}\\n\\n')\n",
    "                for v in L.d(c, otype='verse'):\n",
    "                    verse = T.sectionFromNode(v)[2]\n",
    "                    text = T.text(L.d(v, otype='word'), fmt=fmt)\n",
    "                    fh.write(f'{verse} {text}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "BOOK I_Kings\r\n",
      "\r\n",
      "I_Kings 1\r\n",
      "\r\n",
      "1 ܘ ܡܠܟܐ ܕܘܝܕ ܣܐܒ ܘ ܥܠ ܒ ܫܢܝܐ ܘ ܡܟܣܝܢ ܗܘܘ ܠܗ ܒ ܠܒܘܫܐ ܘ ܠܐ ܫܚܢ \r\n",
      "2 ܘ ܐܡܪܘ ܠܗ ܥܒܕܘܗܝ ܗܐ ܥܒܕܝܟ ܩܕܡܝܟ ܢܒܥܘܢ ܠ ܡܪܢ ܡܠܟܐ ܥܠܝܡܬܐ ܒܬܘܠܬܐ ܘ ܬܩܘܡ ܩܕܡ ܡܠܟܐ ܘ ܬܗܘܐ ܠܗ ܡܫܡܫܢܝܬܐ ܘ ܬܫܟܒ ܒ ܥܘܒܟ ܘ ܢܫܚܢ ܠ ܡܪܢ ܡܠܟܐ \r\n",
      "3 ܘ ܒܥܘ ܥܠܝܡܬܐ ܕ ܫܦܝܪܐ ܒ ܟܠܗ ܬܚܘܡܐ ܕ ܐܝܣܪܝܠ ܘ ܐܫܟܚܘ ܠ ܐܒܝܫܓ ܫܝܠܘܡܝܬܐ ܘ ܐܝܬܝܘܗ ܠ ܡܠܟܐ \r\n",
      "4 ܘ ܥܠܝܡܬܐ ܫܦܝܪܐ ܗܘܬ ܒ ܚܙܘܗ ܛܒ ܘ ܗܘܬ ܠ ܡܠܟܐ ܡܫܡܫܢܝܬܐ ܘ ܡܫܡܫܐ ܠܗ ܘ ܡܠܟܐ ܠܐ ܝܕܥܗ \r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 {thisTemp}/text-orig-full.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "BOOK I_Kings\r\n",
      "\r\n",
      "I_Kings 1\r\n",
      "\r\n",
      "1 W MLK> DWJD S>B W <L B CNJ> W MKSJN HWW LH B LBWC> W L> CXN \r\n",
      "2 W >MRW LH <BDWHJ H> <BDJK QDMJK NB<WN L MRN MLK> <LJMT> BTWLT> W TQWM QDM MLK> W THW> LH MCMCNJT> W TCKB B <WBK W NCXN L MRN MLK> \r\n",
      "3 W B<W <LJMT> D CPJR> B KLH TXWM> D >JSRJL W >CKXW L >BJCG CJLWMJT> W >JTJWH L MLK> \r\n",
      "4 W <LJMT> CPJR> HWT B XZWH VB W HWT L MLK> MCMCNJT> W MCMC> LH W MLK> L> JD<H \r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 {thisTemp}/text-trans-full.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
